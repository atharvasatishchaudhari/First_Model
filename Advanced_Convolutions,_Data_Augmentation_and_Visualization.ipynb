{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atharvasatishchaudhari/First_Model/blob/main/Advanced_Convolutions%2C_Data_Augmentation_and_Visualization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.py\n",
        "\n",
        "from __future__ import print_function\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm\n",
        "\n",
        "# =============================================================================\n",
        "# Set random seed for reproducibility and check for CUDA\n",
        "# =============================================================================\n",
        "SEED = 1\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# =============================================================================\n",
        "# Define Albumentations-based CIFAR10 Dataset wrapper\n",
        "# =============================================================================\n",
        "class AlbumentationsCIFAR10(CIFAR10):\n",
        "    \"\"\"\n",
        "    A custom CIFAR10 dataset that applies albumentations transforms.\n",
        "    The original CIFAR10 __getitem__ returns a PIL image when no transform is provided.\n",
        "    Here we convert the image to a numpy array for albumentations.\n",
        "    \"\"\"\n",
        "    def __init__(self, root, train=True, transform=None, **kwargs):\n",
        "        # Do not pass a transform to the parent class – we will handle it here.\n",
        "        super().__init__(root, train=train, download=True, transform=None)\n",
        "        self.albu_transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Get image and label from CIFAR10's internal data\n",
        "        image, label = self.data[index], int(self.targets[index])\n",
        "        # Convert the image (which is a numpy array in CIFAR10) to uint8 if needed\n",
        "        image = np.array(image)\n",
        "        # Apply albumentations transform if provided\n",
        "        if self.albu_transform:\n",
        "            augmented = self.albu_transform(image=image)\n",
        "            image = augmented['image']\n",
        "        return image, label\n",
        "\n",
        "# =============================================================================\n",
        "# Define Albumentations transformations for training and testing\n",
        "# =============================================================================\n",
        "# CIFAR10 mean and std (for normalization)\n",
        "CIFAR10_MEAN = (0.4914, 0.4822, 0.4465)\n",
        "CIFAR10_STD  = (0.2023, 0.1994, 0.2010)\n",
        "\n",
        "# Training transform: horizontal flip, shiftScaleRotate, coarse dropout, normalization, and conversion to tensor\n",
        "train_transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "    A.CoarseDropout(max_holes=1, max_height=16, max_width=16, min_holes=1,\n",
        "                    min_height=16, min_width=16, fill_value=np.array(CIFAR10_MEAN)*255, p=0.5),\n",
        "    A.Normalize(mean=CIFAR10_MEAN, std=CIFAR10_STD),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# Test transform: only normalization and conversion to tensor\n",
        "test_transform = A.Compose([\n",
        "    A.Normalize(mean=CIFAR10_MEAN, std=CIFAR10_STD),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# =============================================================================\n",
        "# Define the custom network architecture meeting the assignment criteria\n",
        "# =============================================================================\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # --------------------\n",
        "        # Block C1: Standard Convolutions\n",
        "        # Two convolutional layers with 7x7 kernels.\n",
        "        # We use padding=3 to preserve spatial dimensions.\n",
        "        # Input: 3 channels, output: 16 channels.\n",
        "        # This block boosts the receptive field early.\n",
        "        # --------------------\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=7, stride=1, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=7, stride=1, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # --------------------\n",
        "        # Block C2: Depthwise Separable Convolution\n",
        "        # First, a depthwise convolution (groups equal to number of input channels)\n",
        "        # followed by a pointwise (1x1) convolution to increase the channels.\n",
        "        # This block changes channel dimension from 16 to 32.\n",
        "        # --------------------\n",
        "        self.block2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1, groups=16, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # --------------------\n",
        "        # Block C3: Dilated Convolution Block\n",
        "        # Three convolution layers with dilation=4 and 3x3 kernels.\n",
        "        # Using dilation increases the receptive field without increasing the number of parameters significantly.\n",
        "        # Padding is set equal to dilation (i.e. 4) to preserve the feature map size.\n",
        "        # Input and output channels are 32.\n",
        "        # --------------------\n",
        "        self.block3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=4, dilation=4, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=4, dilation=4, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=4, dilation=4, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # --------------------\n",
        "        # Block C40: Downsampling Convolution Block\n",
        "        # A convolution layer with a 7x7 kernel and stride=2 (no max-pooling) to downsample the feature maps.\n",
        "        # It outputs 40 channels (hence “C40”) and further increases the receptive field.\n",
        "        # Padding=3 is used to keep the spatial size appropriate.\n",
        "        # --------------------\n",
        "        self.block4 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=40, kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(40),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        # --------------------\n",
        "        # Global Average Pooling (GAP) and Fully Connected Layer\n",
        "        # GAP reduces each feature map to a single value.\n",
        "        # The final FC layer then maps the 40 features to 10 target classes.\n",
        "        # --------------------\n",
        "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(40, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass the input through each block sequentially.\n",
        "        x = self.block1(x)  # Block C1\n",
        "        x = self.block2(x)  # Block C2 (Depthwise Separable)\n",
        "        x = self.block3(x)  # Block C3 (Dilated Convolutions)\n",
        "        x = self.block4(x)  # Block C40 (Downsampling via conv with stride 2)\n",
        "        x = self.gap(x)     # Global Average Pooling (output shape: [batch, 40, 1, 1])\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output to [batch, 40]\n",
        "        x = self.fc(x)      # Final fully connected layer to get logits for 10 classes\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# =============================================================================\n",
        "# Instantiate the network, print a summary, and prepare DataLoaders\n",
        "# =============================================================================\n",
        "model = Net().to(device)\n",
        "print(\"Model summary:\")\n",
        "summary(model, input_size=(3, 32, 32))  # Prints the torchsummary of the model\n",
        "\n",
        "# Define DataLoader arguments (use a larger batch if CUDA is available)\n",
        "dataloader_args = dict(shuffle=True, batch_size=128, num_workers=4, pin_memory=True) if torch.cuda.is_available() else dict(shuffle=True, batch_size=64)\n",
        "\n",
        "# Create training and test datasets using our Albumentations wrapper\n",
        "train_dataset = AlbumentationsCIFAR10(root='./data', train=True, transform=train_transform)\n",
        "test_dataset  = AlbumentationsCIFAR10(root='./data', train=False, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, **dataloader_args)\n",
        "test_loader  = DataLoader(test_dataset, **dataloader_args)\n",
        "\n",
        "# =============================================================================\n",
        "# Training and Testing Functions\n",
        "# =============================================================================\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    processed = 0\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch} [Train]\")\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "        output = model(data)   # Forward pass\n",
        "        loss = F.nll_loss(output, target)  # Compute negative log-likelihood loss\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        running_loss += loss.item() * data.size(0)\n",
        "        pred = output.argmax(dim=1)\n",
        "        correct += pred.eq(target).sum().item()\n",
        "        processed += len(data)\n",
        "        pbar.set_postfix(loss=loss.item(), accuracy=100.*correct/processed)\n",
        "\n",
        "    epoch_loss = running_loss / processed\n",
        "    epoch_acc = 100. * correct / processed\n",
        "    print(f\"Epoch {epoch} Train Loss: {epoch_loss:.4f} Accuracy: {epoch_acc:.2f}%\")\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def test(model, device, test_loader, epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # Sum losses over batch\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += pred.eq(target).sum().item()\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_acc = 100. * correct / len(test_loader.dataset)\n",
        "    print(f\"Epoch {epoch} Test Loss: {test_loss:.4f} Accuracy: {test_acc:.2f}%\\n\")\n",
        "    return test_loss, test_acc\n",
        "\n",
        "# =============================================================================\n",
        "# Main Training Loop\n",
        "# =============================================================================\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "EPOCHS = 20  # Adjust as needed to achieve 85% accuracy\n",
        "\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss, train_acc = train(model, device, train_loader, optimizer, epoch)\n",
        "    test_loss, test_acc = test(model, device, test_loader, epoch)\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    test_losses.append(test_loss)\n",
        "    test_accuracies.append(test_acc)\n",
        "\n",
        "# =============================================================================\n",
        "# (For assignment QnA)\n",
        "# =============================================================================\n",
        "# 1. Model code from model.py file: (see above)\n",
        "# 2. Torch summary output: The output printed above by torchsummary.\n",
        "# 3. Albumentations transformation code: (see train_transform and test_transform above)\n",
        "# 4. Training log: The training & testing losses/accuracy printed each epoch.\n",
        "# 5. README.md: Please see the GitHub repository README at:\n",
        "#    https://github.com/yourusername/S9-Assignment-Solution\n"
      ],
      "metadata": {
        "id": "DCzyPYQuO19J",
        "outputId": "f798d7c7-e76a-4d6a-844f-ba2d68a06397",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n",
            "<ipython-input-1-60c49f68a014>:64: UserWarning: Argument(s) 'max_holes, max_height, max_width, min_holes, min_height, min_width, fill_value' are not valid for transform CoarseDropout\n",
            "  A.CoarseDropout(max_holes=1, max_height=16, max_width=16, min_holes=1,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model summary:\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]           2,352\n",
            "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
            "              ReLU-3           [-1, 16, 32, 32]               0\n",
            "            Conv2d-4           [-1, 16, 32, 32]          12,544\n",
            "       BatchNorm2d-5           [-1, 16, 32, 32]              32\n",
            "              ReLU-6           [-1, 16, 32, 32]               0\n",
            "            Conv2d-7           [-1, 16, 32, 32]             144\n",
            "       BatchNorm2d-8           [-1, 16, 32, 32]              32\n",
            "              ReLU-9           [-1, 16, 32, 32]               0\n",
            "           Conv2d-10           [-1, 32, 32, 32]             512\n",
            "      BatchNorm2d-11           [-1, 32, 32, 32]              64\n",
            "             ReLU-12           [-1, 32, 32, 32]               0\n",
            "           Conv2d-13           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-14           [-1, 32, 32, 32]              64\n",
            "             ReLU-15           [-1, 32, 32, 32]               0\n",
            "           Conv2d-16           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-17           [-1, 32, 32, 32]              64\n",
            "             ReLU-18           [-1, 32, 32, 32]               0\n",
            "           Conv2d-19           [-1, 32, 32, 32]           9,216\n",
            "      BatchNorm2d-20           [-1, 32, 32, 32]              64\n",
            "             ReLU-21           [-1, 32, 32, 32]               0\n",
            "           Conv2d-22           [-1, 40, 16, 16]          62,720\n",
            "      BatchNorm2d-23           [-1, 40, 16, 16]              80\n",
            "             ReLU-24           [-1, 40, 16, 16]               0\n",
            "AdaptiveAvgPool2d-25             [-1, 40, 1, 1]               0\n",
            "           Linear-26                   [-1, 10]             410\n",
            "================================================================\n",
            "Total params: 106,762\n",
            "Trainable params: 106,762\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 4.36\n",
            "Params size (MB): 0.41\n",
            "Estimated Total Size (MB): 4.78\n",
            "----------------------------------------------------------------\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:05<00:00, 28.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 1 [Train]: 100%|██████████| 391/391 [00:29<00:00, 13.16it/s, accuracy=37.8, loss=1.42]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Train Loss: 1.6767 Accuracy: 37.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Test Loss: 1.5883 Accuracy: 40.15%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2 [Train]: 100%|██████████| 391/391 [00:21<00:00, 18.56it/s, accuracy=52.4, loss=0.98]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Train Loss: 1.3104 Accuracy: 52.44%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Test Loss: 1.3916 Accuracy: 51.76%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3 [Train]: 100%|██████████| 391/391 [00:21<00:00, 18.58it/s, accuracy=58.9, loss=0.862]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Train Loss: 1.1393 Accuracy: 58.92%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Test Loss: 1.1390 Accuracy: 58.44%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4 [Train]: 100%|██████████| 391/391 [00:19<00:00, 20.05it/s, accuracy=63, loss=0.942]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Train Loss: 1.0302 Accuracy: 63.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Test Loss: 1.0689 Accuracy: 62.19%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5 [Train]: 100%|██████████| 391/391 [00:20<00:00, 18.73it/s, accuracy=65.8, loss=0.908]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Train Loss: 0.9608 Accuracy: 65.77%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Test Loss: 0.9909 Accuracy: 64.46%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6 [Train]: 100%|██████████| 391/391 [00:19<00:00, 19.70it/s, accuracy=67.5, loss=0.846]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Train Loss: 0.9110 Accuracy: 67.52%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Test Loss: 0.8918 Accuracy: 68.35%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7 [Train]: 100%|██████████| 391/391 [00:19<00:00, 19.93it/s, accuracy=69.8, loss=0.919]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Train Loss: 0.8603 Accuracy: 69.80%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Test Loss: 0.9218 Accuracy: 67.75%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8 [Train]: 100%|██████████| 391/391 [00:20<00:00, 18.94it/s, accuracy=70.9, loss=0.823]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Train Loss: 0.8208 Accuracy: 70.93%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Test Loss: 0.8377 Accuracy: 69.94%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9 [Train]: 100%|██████████| 391/391 [00:19<00:00, 20.14it/s, accuracy=72, loss=0.774]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Train Loss: 0.7931 Accuracy: 72.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Test Loss: 0.8593 Accuracy: 69.94%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10 [Train]: 100%|██████████| 391/391 [00:19<00:00, 19.77it/s, accuracy=73.3, loss=0.698]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Train Loss: 0.7616 Accuracy: 73.35%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Test Loss: 0.8748 Accuracy: 69.52%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11 [Train]: 100%|██████████| 391/391 [00:20<00:00, 19.04it/s, accuracy=74.2, loss=0.859]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Train Loss: 0.7384 Accuracy: 74.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Test Loss: 0.7129 Accuracy: 75.11%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12 [Train]: 100%|██████████| 391/391 [00:19<00:00, 19.77it/s, accuracy=74.9, loss=0.673]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 Train Loss: 0.7159 Accuracy: 74.85%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 Test Loss: 0.7461 Accuracy: 74.40%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13 [Train]: 100%|██████████| 391/391 [00:20<00:00, 18.71it/s, accuracy=75.4, loss=0.737]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 Train Loss: 0.6955 Accuracy: 75.45%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 Test Loss: 0.7370 Accuracy: 74.80%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14 [Train]: 100%|██████████| 391/391 [00:20<00:00, 18.93it/s, accuracy=76.1, loss=0.695]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 Train Loss: 0.6814 Accuracy: 76.13%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 Test Loss: 0.8075 Accuracy: 72.52%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15 [Train]: 100%|██████████| 391/391 [00:19<00:00, 19.78it/s, accuracy=76.5, loss=0.795]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 Train Loss: 0.6684 Accuracy: 76.47%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 Test Loss: 0.6569 Accuracy: 77.42%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16 [Train]: 100%|██████████| 391/391 [00:20<00:00, 18.86it/s, accuracy=77.2, loss=0.511]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 Train Loss: 0.6522 Accuracy: 77.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 Test Loss: 0.6603 Accuracy: 77.00%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17 [Train]: 100%|██████████| 391/391 [00:20<00:00, 19.23it/s, accuracy=77.6, loss=0.724]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 Train Loss: 0.6384 Accuracy: 77.60%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 Test Loss: 0.6926 Accuracy: 76.23%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18 [Train]: 100%|██████████| 391/391 [00:20<00:00, 19.45it/s, accuracy=78.2, loss=0.559]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 Train Loss: 0.6268 Accuracy: 78.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 Test Loss: 0.6834 Accuracy: 76.17%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19 [Train]: 100%|██████████| 391/391 [00:20<00:00, 18.74it/s, accuracy=78.5, loss=0.587]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 Train Loss: 0.6174 Accuracy: 78.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 Test Loss: 0.6760 Accuracy: 76.65%\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20 [Train]: 100%|██████████| 391/391 [00:20<00:00, 19.49it/s, accuracy=78.8, loss=0.676]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 Train Loss: 0.6079 Accuracy: 78.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 Test Loss: 0.7708 Accuracy: 73.33%\n",
            "\n"
          ]
        }
      ]
    }
  ]
}